{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification\n",
    "\n",
    "#### By Bhupesh Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-3 : Data Cleaning and Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import regex as re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Weekly Tech Support Thread - [July 09]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Important Announcement + Mod Applications</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Well Why Not ðŸ˜€</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Paid apps actually worth it in 2019?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My iPhone collection as of yesterday! Just mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         post_title  rank\n",
       "0           0             Weekly Tech Support Thread - [July 09]     0\n",
       "1           1          Important Announcement + Mod Applications     0\n",
       "2           2                                     Well Why Not ðŸ˜€     0\n",
       "3           3               Paid apps actually worth it in 2019?     0\n",
       "4           4  My iPhone collection as of yesterday! Just mis...     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('raw_title_dataset')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekly Tech Support Thread - [July 09]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Important Announcement + Mod Applications</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well Why Not ðŸ˜€</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paid apps actually worth it in 2019?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My iPhone collection as of yesterday! Just mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title  rank\n",
       "0             Weekly Tech Support Thread - [July 09]     0\n",
       "1          Important Announcement + Mod Applications     0\n",
       "2                                     Well Why Not ðŸ˜€     0\n",
       "3               Paid apps actually worth it in 2019?     0\n",
       "4  My iPhone collection as of yesterday! Just mis...     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>3 XL Asurion replacement: should I expect the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>The Pixel 3a disappointing design decisions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>Pixel 3a screen protector</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>Does anyone know how I can sync my pictures fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>do I have to give up Pixel XL original photos ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_title  rank\n",
       "1802  3 XL Asurion replacement: should I expect the ...     1\n",
       "1803        The Pixel 3a disappointing design decisions     1\n",
       "1804                          Pixel 3a screen protector     1\n",
       "1805  Does anyone know how I can sync my pictures fr...     1\n",
       "1806  do I have to give up Pixel XL original photos ...     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1807, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(posts):\n",
    "    # Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", posts)\n",
    "    \n",
    "    #  Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['post_title'] = dataset.apply(lambda x: clean_posts(x['post_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weekly tech support thread july</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>important announcement mod applications</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well why not</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid apps actually worth it in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my iphone collection as of yesterday just miss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title  rank\n",
       "0                    weekly tech support thread july     0\n",
       "1            important announcement mod applications     0\n",
       "2                                       well why not     0\n",
       "3                     paid apps actually worth it in     0\n",
       "4  my iphone collection as of yesterday just miss...     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>xl asurion replacement should i expect the ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>the pixel a disappointing design decisions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>pixel a screen protector</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>does anyone know how i can sync my pictures fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>do i have to give up pixel xl original photos ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_title  rank\n",
       "1802  xl asurion replacement should i expect the ver...     1\n",
       "1803         the pixel a disappointing design decisions     1\n",
       "1804                           pixel a screen protector     1\n",
       "1805  does anyone know how i can sync my pictures fr...     1\n",
       "1806  do i have to give up pixel xl original photos ...     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_title    0\n",
       "rank          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['post_title']\n",
    "y = dataset['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501384\n",
       "0    0.498616\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I can see the baseling score is almsot 50/50. which is good because our data is balaced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                  random_state =42,\n",
    "                                                 stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling \n",
    "\n",
    "I am going to be using two models to train and test the data, Logistic Regression and Multinomial Naive Bayes. \n",
    "\n",
    "I will also use CountVectorizer with No stop words, English stop words and custom stop words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer and tranforming it into matrix\n",
    "X_train_cv = count_vec.fit_transform(X_train)\n",
    "X_test_cv = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 2238)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 2238)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'about', 'absolute', 'access', 'accessibility', 'accessories', 'accidental', 'accidentally', 'account', 'accuracy', 'accused', 'across', 'act', 'acting', 'action', 'activate', 'activated', 'activation', 'active', 'actually', 'adapter', 'adaptor', 'adb', 'add', 'added', 'adding', 'additional', 'address', 'adds', 'adhesive', 'adjustment', 'adopt', 'ads', 'advanced', 'advice', 'affect', 'afford', 'after', 'afternoon', 'again', 'age', 'ago', 'agrees', 'ahead', 'ain', 'air', 'airdrop', 'airplay', 'airpods', 'alarm', 'alarms', 'album', 'albums', 'alert', 'alerts', 'aliexpress', 'all', 'allow', 'allowed', 'allows', 'almost', 'already', 'also', 'alternative', 'always', 'am', 'amazon', 'ambient', 'amoled', 'among', 'amount', 'amp', 'an', 'analyzing', 'and', 'andriod', 'android', 'anew', 'angle', 'animation', 'animoji', 'annoying', 'another', 'answer', 'antena', 'any', 'anybody', 'anyone', 'anything', 'anytime', 'anyway', 'anywhere', 'aod', 'apk', 'app', 'apparently', 'appeared', 'appears', 'apple', 'applecare', 'apples', 'apps', 'appstore', 'appvally', 'are', 'aren', 'armor', 'arrangement', 'art', 'artist', 'as', 'asap', 'asking', 'assistant', 'assurant', 'at', 'attach', 'attention', 'atv', 'audible', 'audio', 'australia', 'auto', 'autocorrect', 'autofocus', 'automatic', 'automatically', 'automation', 'autoshutdown', 'aux', 'availability', 'available', 'away', 'axl', 'back', 'background', 'backup', 'bad', 'bait', 'baking', 'balance', 'bands', 'bank', 'bar', 'based', 'battery', 'be', 'beast', 'beautiful', 'because', 'become', 'becomes', 'becoming', 'bed', 'been', 'before', 'beginning', 'behaving', 'behavior', 'being', 'believer', 'belkin', 'besides', 'best', 'bestbuy', 'beta', 'betas', 'better', 'between', 'big', 'billboard', 'bit', 'black', 'blacklist', 'blends', 'blobs', 'blown', 'blue', 'bluetooth', 'blurry', 'body', 'boiling', 'bomb', 'bookmark', 'boom', 'boot', 'booted', 'booth', 'booting', 'bootloop', 'boring', 'bose', 'both', 'bottom', 'bought', 'bowl', 'box', 'boys', 'brand', 'brick', 'bricked', 'bricks', 'briefly', 'bright', 'brightening', 'brightness', 'bringing', 'brings', 'broke', 'broken', 'brother', 'brothers', 'brought', 'brown', 'browse', 'browser', 'bubbles', 'bud', 'budget', 'buds', 'bug', 'buggy', 'bugs', 'bulk', 'bulky', 'bum', 'bumper', 'bunch', 'burn', 'burned', 'business', 'but', 'butt', 'button', 'buttons', 'buy', 'buyer', 'buying', 'buzz', 'by', 'cable', 'cables', 'cache', 'calendar', 'calender', 'call', 'called', 'caller', 'callers', 'calling', 'calls', 'came', 'camera', 'cameras', 'camping', 'can', 'canada', 'cannot', 'cant', 'capabilities', 'capacity', 'caps', 'captive', 'captiveportal', 'captiveportallogin', 'car', 'card', 'cards', 'care', 'carplay', 'carrier', 'carriers', 'carrying', 'carts', 'case', 'cases', 'cat', 'catch', 'cats', 'cause', 'caused', 'causing', 'cc', 'cell', 'cellular', 'center', 'centre', 'certain', 'chances', 'change', 'changed', 'changes', 'changing', 'charge', 'charged', 'charger', 'chargers', 'charges', 'charging', 'chart', 'chase', 'chat', 'cheap', 'cheaper', 'check', 'checked', 'checking', 'cheerful', 'child', 'chin', 'china', 'choice', 'choices', 'choose', 'chris', 'chroma', 'chrome', 'chromebook', 'chromecast', 'circle', 'city', 'claims', 'clash', 'clean', 'cleaned', 'clear', 'clearing', 'clearplex', 'click', 'clickable', 'client', 'clock', 'close', 'closed', 'closer', 'closes', 'club', 'coating', 'code', 'collection', 'color', 'colorful', 'combine', 'come', 'comes', 'coming', 'commands', 'comment', 'comments', 'company', 'compare', 'compared', 'compass', 'compatibility', 'compatible', 'complete', 'completed', 'completely', 'computer', 'computers', 'concept', 'concert', 'condensation', 'condition', 'configuration', 'confused', 'confusion', 'connect', 'connected', 'connecting', 'connection', 'connections', 'connectivity', 'connector', 'cons', 'consequences', 'considering', 'contact', 'contacting', 'contacts', 'contemplating', 'content', 'continue', 'continuously', 'contract', 'contrast', 'control', 'controller', 'controlling', 'controls', 'controversial', 'conversation', 'cool', 'cooled', 'copy', 'cord', 'corner', 'corners', 'correction', 'corrupt', 'cost', 'costing', 'costs', 'could', 'couldn', 'country', 'couple', 'cousin', 'cover', 'covered', 'covers', 'cpu', 'crack', 'cracked', 'crackling', 'craig', 'crapped', 'crash', 'crashed', 'crashes', 'crashing', 'crazy', 'create', 'created', 'credit', 'crop', 'cruash', 'crush', 'cs', 'current', 'currently', 'custom', 'customer', 'customers', 'cut', 'cutouts', 'cuts', 'cycling', 'daily', 'damage', 'dammit', 'damn', 'dark', 'data', 'date', 'daughter', 'day', 'days', 'dbrand', 'de', 'deactivated', 'dead', 'deal', 'dealing', 'deals', 'decide', 'decided', 'decisions', 'decreased', 'default', 'defects', 'defender', 'definitely', 'definition', 'degradation', 'degraded', 'delayed', 'delays', 'delete', 'deleted', 'denizens', 'denying', 'departure', 'descriptions', 'design', 'designer', 'desktop', 'detail', 'details', 'detected', 'deteriorating', 'deterioration', 'dev', 'developer', 'developers', 'device', 'devices', 'devs', 'dialed', 'dialing', 'dictionary', 'did', 'didn', 'died', 'difference', 'differences', 'different', 'difficulty', 'digital', 'dilemma', 'dimmer', 'dip', 'directly', 'dirt', 'disable', 'disabled', 'disabling', 'disappear', 'disappeared', 'disappearing', 'disappointed', 'disappointing', 'discoloration', 'disconnected', 'disconnecting', 'discontinued', 'discontinuing', 'discount', 'discounted', 'discover', 'discovering', 'discovery', 'discussion', 'display', 'displaying', 'distortion', 'do', 'dock', 'doctor', 'does', 'doesn', 'doesnt', 'dogfood', 'doing', 'dome', 'don', 'done', 'dongle', 'dosent', 'dot', 'dots', 'double', 'down', 'downgrade', 'downgrading', 'download', 'downloading', 'downloadsubscription', 'dpreview', 'drag', 'drain', 'draining', 'drains', 'dream', 'drive', 'driver', 'drivers', 'drives', 'drop', 'dropbox', 'dropped', 'dropping', 'drops', 'dsabled', 'dsds', 'dual', 'dude', 'due', 'dull', 'dumb', 'dumping', 'duplicate', 'durable', 'during', 'dust', 'dynamex', 'each', 'earbuds', 'earlier', 'earpiece', 'earthquake', 'easier', 'easily', 'ebay', 'edge', 'effect', 'either', 'eleven', 'eliminate', 'elite', 'else', 'elses', 'email', 'emergency', 'emoji', 'emojis', 'empty', 'enable', 'endurance', 'enough', 'entire', 'equalizer', 'equivalent', 'erase', 'erasing', 'erratic', 'error', 'es', 'esim', 'etc', 'euiccmanager', 'europe', 'even', 'events', 'ever', 'every', 'everyone', 'everything', 'ex', 'example', 'except', 'exchange', 'excited', 'exclusive', 'exist', 'exists', 'expect', 'expensive', 'experience', 'experienced', 'experiences', 'experts', 'explain', 'export', 'exporting', 'exposed', 'exposes', 'external', 'externally', 'extract', 'extremely', 'eye', 'eyes', 'eyesight', 'fabric', 'face', 'faceid', 'facetime', 'fact', 'factory', 'faded', 'fail', 'failed', 'failing', 'fails', 'fair', 'fake', 'fall', 'falling', 'falls', 'families', 'family', 'far', 'fast', 'faster', 'father', 'faulty', 'favorite', 'favourite', 'fb', 'feature', 'features', 'feed', 'feedback', 'feel', 'fell', 'fellas', 'fellow', 'few', 'fi', 'figure', 'file', 'files', 'filter', 'finally', 'find', 'finding', 'finds', 'fine', 'finger', 'fingerprint', 'fingers', 'finicky', 'finished', 'fire', 'first', 'fit', 'fix', 'fixed', 'flash', 'flashes', 'flashing', 'floors', 'fmi', 'fo', 'focuing', 'focus', 'focusing', 'fog', 'folder', 'follow', 'follows', 'font', 'footsteps', 'for', 'force', 'forced', 'forever', 'forgive', 'forgot', 'former', 'forward', 'found', 'foundation', 'fps', 'frame', 'france', 'freak', 'free', 'freely', 'freezes', 'freezing', 'frequent', 'frequently', 'fresh', 'friend', 'friendly', 'friends', 'fro', 'from', 'front', 'frozen', 'frustrating', 'fuck', 'full', 'fully', 'fun', 'function', 'functioning', 'fundamental', 'futuristic', 'fuzz', 'fyi', 'galaxy', 'galileo', 'gallery', 'game', 'games', 'garbage', 'gb', 'gboard', 'gcam', 'geekbench', 'gel', 'gen', 'generation', 'gently', 'gestural', 'gestures', 'get', 'gets', 'getting', 'ghostek', 'giant', 'gif', 'gift', 'girlfriend', 'give', 'giveaway', 'gives', 'glance', 'glass', 'glitch', 'glorious', 'glow', 'gmail', 'go', 'goes', 'going', 'gold', 'gone', 'gonna', 'good', 'goodbye', 'google', 'googlepixel', 'got', 'gps', 'grab', 'grade', 'gradient', 'grainy', 'grandiose', 'graph', 'graphic', 'great', 'green', 'greeting', 'greetings', 'grew', 'grey', 'grinding', 'group', 'groups', 'gs', 'guess', 'guesses', 'guest', 'guy', 'guys', 'hack', 'had', 'halt', 'hand', 'handed', 'handoff', 'hands', 'hangs', 'happen', 'happened', 'happening', 'happy', 'haptic', 'hard', 'hardware', 'has', 'hasn', 'hate', 'have', 'haven', 'having', 'hdmi', 'hdr', 'he', 'head', 'headphone', 'headphones', 'heads', 'headset', 'health', 'healthy', 'hear', 'hearing', 'heating', 'heats', 'heavily', 'heavy', 'hello', 'help', 'helps', 'her', 'here', 'hi', 'hiding', 'high', 'him', 'hints', 'his', 'history', 'hmmm', 'hold', 'holder', 'holding', 'holiday', 'home', 'homepod', 'homescreen', 'hook', 'hopefully', 'hoping', 'horizontal', 'hot', 'hotel', 'hotkey', 'hour', 'hours', 'housing', 'how', 'huawei', 'hung', 'hyperlink', 'iclarified', 'icloud', 'icloudbacked', 'icon', 'icons', 'id', 'idea', 'ideas', 'idk', 'if', 'ifttt', 'igloo', 'im', 'image', 'images', 'imagine', 'imessage', 'imessages', 'immediately', 'imovie', 'impact', 'implementation', 'implemented', 'imply', 'imported', 'impossible', 'impressed', 'impressive', 'improve', 'improved', 'improvement', 'improvements', 'in', 'inaccuracy', 'inaccurate', 'inch', 'include', 'including', 'incoming', 'inconsistent', 'increase', 'increased', 'incredibly', 'india', 'inexperienced', 'info', 'information', 'input', 'inputs', 'inside', 'insta', 'instagram', 'install', 'installed', 'instant', 'instantly', 'instead', 'integration', 'intended', 'intensity', 'interested', 'interesting', 'interface', 'internals', 'international', 'internet', 'into', 'introduced', 'intrusive', 'invisible', 'invisiglass', 'ios', 'ip', 'ipad', 'ipads', 'iphone', 'iphones', 'iphonex', 'ipsw', 'irc', 'is', 'isn', 'iso', 'issue', 'issues', 'it', 'items', 'its', 'itself', 'itunes', 'ive', 'iwatch', 'jabra', 'jack', 'jailbreak', 'jailbroken', 'jet', 'jobs', 'joining', 'jon', 'july', 'jumping', 'june', 'just', 'keep', 'keeps', 'keitai', 'kernel', 'key', 'keyboard', 'keynote', 'keys', 'kill', 'killed', 'kills', 'kind', 'kinda', 'kit', 'km', 'knew', 'know', 'kove', 'laggy', 'landline', 'landscape', 'lap', 'large', 'largest', 'last', 'lasted', 'lastu', 'lately', 'latency', 'later', 'latest', 'launch', 'launcher', 'layouts', 'lcd', 'leading', 'leak', 'leaked', 'leaks', 'leaksbygoogle', 'least', 'leather', 'led', 'left', 'legit', 'legs', 'lens', 'leopard', 'less', 'let', 'lets', 'letter', 'level', 'lg', 'license', 'life', 'light', 'lightning', 'like', 'lines', 'lineup', 'link', 'linked', 'links', 'lirum', 'listen', 'listening', 'lite', 'little', 'live', 'll', 'load', 'location', 'locations', 'lock', 'locked', 'locks', 'login', 'logo', 'long', 'longer', 'longevity', 'look', 'looked', 'looking', 'looks', 'loop', 'lose', 'losing', 'loss', 'lost', 'lot', 'lottery', 'loud', 'love', 'low', 'lower', 'lowest', 'lte', 'luminous', 'lyrics', 'mac', 'macbook', 'macbooks', 'made', 'magic', 'magisk', 'magnetic', 'mail', 'mailing', 'main', 'major', 'make', 'makes', 'making', 'malformed', 'manage', 'management', 'manager', 'managing', 'many', 'mappings', 'maps', 'march', 'mario', 'mark', 'marked', 'marking', 'markup', 'match', 'matching', 'matoran', 'matte', 'matter', 'max', 'maximum', 'mb', 'mctube', 'mdm', 'me', 'means', 'media', 'megathread', 'members', 'memo', 'memories', 'memos', 'menu', 'mess', 'message', 'messages', 'messaging', 'messenger', 'messing', 'mic', 'microphone', 'microsoft', 'mid', 'might', 'migrating', 'mind', 'mine', 'mini', 'minimizing', 'mins', 'minutes', 'misleading', 'miss', 'missing', 'mixer', 'mm', 'mobile', 'mod', 'mode', 'model', 'models', 'modem', 'modern', 'module', 'moisture', 'mom', 'moment', 'moms', 'mon', 'money', 'month', 'monthly', 'months', 'more', 'morning', 'most', 'mount', 'mous', 'move', 'moved', 'moving', 'mp', 'much', 'muffled', 'multiple', 'multiples', 'music', 'musicians', 'must', 'mute', 'my', 'name', 'names', 'nap', 'native', 'nav', 'navigation', 'nch', 'near', 'nearly', 'necessary', 'need', 'needed', 'needs', 'nervous', 'network', 'networks', 'never', 'new', 'newer', 'news', 'next', 'nexus', 'nfc', 'nice', 'night', 'nightsight', 'nintendo', 'no', 'noise', 'non', 'nonsense', 'normal', 'normally', 'not', 'notch', 'notches', 'note', 'notes', 'nothing', 'notice', 'noticeable', 'noticeably', 'noticed', 'notification', 'notifications', 'november', 'now', 'nowadays', 'nowhere', 'number', 'numbers', 'nuts', 'nylon', 'oc', 'ocr', 'odin', 'oem', 'of', 'off', 'offer', 'offering', 'official', 'officially', 'often', 'og', 'ok', 'okay', 'old', 'older', 'oldest', 'oldschool', 'oled', 'oleophobic', 'on', 'once', 'one', 'oneplus', 'ones', 'online', 'only', 'onto', 'op', 'open', 'opened', 'openid', 'opening', 'opinions', 'optimized', 'option', 'options', 'or', 'order', 'ordering', 'organize', 'organized', 'original', 'originality', 'os', 'osaifu', 'ota', 'otao', 'other', 'otherwise', 'otter', 'otterbox', 'our', 'out', 'over', 'overheated', 'overheating', 'overseas', 'own', 'owned', 'owner', 'owners', 'package', 'page', 'paid', 'pair', 'paper', 'part', 'partially', 'partner', 'parts', 'party', 'passcode', 'password', 'paste', 'patch', 'patina', 'pause', 'paused', 'pausing', 'paw', 'pay', 'payment', 'pc', 'pd', 'pdfs', 'peak', 'peculiar', 'peeve', 'pen', 'people', 'per', 'percentage', 'performance', 'perhaps', 'period', 'periodically', 'permanently', 'person', 'pet', 'phone', 'phones', 'photo', 'photos', 'photosphere', 'phrases', 'physically', 'pick', 'picked', 'pickup', 'pics', 'picture', 'pictures', 'pie', 'pinch', 'pixel', 'pixelbook', 'pixelbuds', 'pixels', 'pixle', 'place', 'plain', 'plan', 'planning', 'plans', 'planting', 'plastic', 'play', 'player', 'playground', 'playing', 'playlist', 'playlists', 'plays', 'pleasantly', 'please', 'plug', 'plugged', 'plugs', 'plus', 'plz', 'pocket', 'pockets', 'podcast', 'point', 'pointless', 'pok', 'poll', 'pool', 'poor', 'pop', 'popped', 'popping', 'popups', 'port', 'portable', 'portal', 'portraits', 'ports', 'possible', 'possibly', 'possiple', 'post', 'posted', 'posting', 'power', 'powerbeats', 'powering', 'powers', 'prefer', 'preferred', 'prepaid', 'preparing', 'presenting', 'presidio', 'press', 'pressing', 'pretty', 'prevalent', 'prevent', 'preview', 'previews', 'previous', 'previously', 'price', 'prices', 'pricing', 'primary', 'prime', 'print', 'printed', 'priority', 'pristine', 'privacy', 'pro', 'prob', 'probably', 'problem', 'problems', 'process', 'processes', 'produce', 'profanity', 'professional', 'profile', 'program', 'project', 'promising', 'promo', 'promotion', 'promotional', 'prompts', 'properly', 'pros', 'protect', 'protection', 'protector', 'protectors', 'protects', 'prove', 'provider', 'proximity', 'psa', 'pubg', 'public', 'puchase', 'pun', 'purchase', 'purchased', 'purpose', 'put', 'pw', 'qpp', 'qr', 'qualcomm', 'quality', 'question', 'questions', 'queue', 'quick', 'quicker', 'quickly', 'quid', 'quite', 'radiation', 'radio', 'radios', 'ram', 'ran', 'random', 'randomly', 'rant', 'rapidly', 'rather', 'ratio', 'ravpower', 'ray', 'rd', 're', 'read', 'reader', 'ready', 'real', 'really', 'reappearing', 'rear', 'reason', 'reboot', 'rebuilding', 'rebuilt', 'recalled', 'receipts', 'receive', 'received', 'receiver', 'receiving', 'recent', 'recently', 'recharging', 'recognise', 'recommend', 'recommendation', 'record', 'recording', 'recover', 'recovery', 'red', 'reddish', 'reddit', 'redditor', 'redditors', 'reduce', 'reduced', 'redundant', 'referral', 'refixed', 'refreshing', 'refurbished', 'refusing', 'reg', 'regarding', 'regardless', 'region', 'register', 'release', 'released', 'relevant', 'reliable', 'relocking', 'remain', 'remap', 'reminder', 'reminders', 'remove', 'removing', 'renaming', 'render', 'renders', 'renewed', 'reoccuring', 'repair', 'repaired', 'replace', 'replaceable', 'replaced', 'replacement', 'replaces', 'replacing', 'report', 'reportedly', 'reporting', 'request', 'requested', 'require', 'res', 'reset', 'resistance', 'resistant', 'response', 'respring', 'restarts', 'restore', 'restoring', 'results', 'retrieve', 'retrieving', 'retro', 'return', 'returning', 'reveal', 'reversible', 'revert', 'review', 'reviews', 'rhinoshield', 'ribbon', 'rid', 'ride', 'ridiculous', 'ridiculously', 'right', 'rigid', 'ring', 'ringer', 'ringing', 'ringtone', 'ringtones', 'rip', 'risk', 'risks', 'rma', 'road', 'roaming', 'robocalls', 'rockin', 'rocking', 'roll', 'rolling', 'room', 'root', 'rooted', 'rooting', 'rosenblatt', 'rotate', 'route', 'router', 'routine', 'routines', 'row', 'royale', 'rtn', 'rudberg', 'rumor', 'rumored', 'rumors', 'run', 'running', 'saddle', 'safari', 'safe', 'safiest', 'sale', 'sales', 'same', 'samples', 'samsung', 'samsungs', 'sand', 'sar', 'save', 'saved', 'saver', 'saves', 'saving', 'say', 'saying', 'says', 'scam', 'score', 'scratch', 'scratches', 'screen', 'screening', 'screens', 'screenshots', 'screwed', 'scroll', 'scrolling', 'se', 'seamless', 'search', 'searching', 'second', 'secondhand', 'seconds', 'section', 'secure', 'security', 'see', 'seeking', 'seem', 'seems', 'seen', 'select', 'selected', 'self', 'selfie', 'sell', 'seller', 'selling', 'send', 'sending', 'sends', 'sense', 'sensitive', 'sensor', 'sent', 'separate', 'september', 'series', 'serious', 'serve', 'server', 'service', 'services', 'set', 'setting', 'settings', 'setup', 'several', 'shaking', 'share', 'sharing', 'sharp', 'shazam', 'she', 'shelf', 'shift', 'shiftcam', 'shipping', 'shirt', 'shock', 'shopping', 'short', 'shortage', 'shorts', 'should', 'shouldn', 'show', 'showed', 'showing', 'shows', 'shrinks', 'shsh', 'shutdown', 'shutoff', 'shuts', 'shutter', 'sideloading', 'sides', 'sideways', 'sienna', 'sight', 'sign', 'signal', 'significant', 'significantly', 'silence', 'silicone', 'silly', 'silver', 'sim', 'simple', 'simply', 'simultaneously', 'since', 'single', 'siri', 'site', 'size', 'sizes', 'skin', 'skins', 'sleep', 'sleeper', 'slick', 'slide', 'slides', 'slow', 'slowdown', 'slower', 'slowest', 'slowly', 'small', 'smallest', 'smart', 'smartphone', 'smashed', 'smh', 'smoothie', 'sms', 'snapchat', 'snooze', 'snorkeling', 'so', 'soft', 'software', 'sold', 'solidsuit', 'solution', 'solutions', 'solved', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometimes', 'song', 'songs', 'soon', 'sort', 'sound', 'sounds', 'source', 'space', 'spammed', 'speaker', 'speakerphone', 'speakers', 'specially', 'specific', 'speck', 'speech', 'spending', 'spigen', 'spinning', 'splitter', 'spontaneous', 'spot', 'spotify', 'spotlight', 'square', 'squeeze', 'st', 'stabilization', 'stadia', 'stains', 'stand', 'staring', 'start', 'started', 'starts', 'statement', 'static', 'stats', 'stay', 'staying', 'stealth', 'steve', 'stickie', 'still', 'stitch', 'stock', 'stolen', 'stop', 'stopped', 'stopping', 'stops', 'storage', 'store', 'strange', 'stress', 'stuck', 'study', 'stupid', 'stupidly', 'style', 'stylo', 'sub', 'subreddit', 'subscription', 'success', 'sucks', 'sudden', 'suddenly', 'sued', 'suggestion', 'suggestions', 'sun', 'suold', 'supcase', 'super', 'superthread', 'support', 'supports', 'sure', 'surprised', 'survey', 'survives', 'sustain', 'swamp', 'swap', 'swappa', 'swarm', 'swear', 'swipe', 'swiping', 'switch', 'switched', 'switcher', 'switching', 'swith', 'swp', 'symmetry', 'symptoms', 'sync', 'synchrony', 'system', 'tab', 'take', 'taken', 'taking', 'talk', 'tap', 'tape', 'tapping', 'team', 'tech', 'techradar', 'telephoto', 'tell', 'tells', 'tempered', 'terms', 'terrible', 'terribly', 'tether', 'tethering', 'text', 'texting', 'texts', 'textured', 'tforce', 'th', 'than', 'thanks', 'that', 'the', 'their', 'theirs', 'them', 'theme', 'then', 'there', 'these', 'they', 'thin', 'thing', 'things', 'think', 'thinking', 'thinks', 'thinnest', 'this', 'tho', 'those', 'though', 'thought', 'thoughts', 'thread', 'through', 'throughout', 'thru', 'til', 'till', 'time', 'times', 'tint', 'tip', 'tips', 'title', 'titles', 'tmobile', 'to', 'toast', 'today', 'together', 'toggle', 'told', 'tone', 'too', 'top', 'topics', 'torch', 'toronto', 'total', 'touch', 'touchid', 'touching', 'touchscreen', 'tough', 'toyota', 'tozo', 'track', 'trade', 'transfer', 'transferring', 'transparent', 'traveling', 'treasure', 'tree', 'trend', 'trial', 'tricks', 'tried', 'tries', 'triple', 'trolls', 'trouble', 'troubleshooting', 'true', 'truedepth', 'try', 'trying', 'tubex', 'tubie', 'turn', 'turned', 'turning', 'turns', 'tv', 'tweak', 'twice', 'two', 'twrp', 'tws', 'type', 'typing', 'ue', 'ui', 'uk', 'umm', 'unable', 'unavailable', 'under', 'underrated', 'underwater', 'unexpected', 'unfreeze', 'ungroup', 'unimaginable', 'uninstall', 'unique', 'unit', 'unknown', 'unless', 'unlock', 'unlocked', 'unlocking', 'unpaid', 'unresponsive', 'unrooted', 'unstable', 'unthinkable', 'until', 'unusable', 'uodated', 'up', 'upcoming', 'update', 'updated', 'updates', 'updating', 'upgrade', 'upgraded', 'upgrading', 'upload', 'uploading', 'ups', 'urgent', 'url', 'us', 'usability', 'usable', 'usage', 'usb', 'use', 'used', 'useful', 'useless', 'user', 'users', 'uses', 'using', 'usually', 'valid', 'value', 'vanished', 'variant', 've', 'verge', 'verification', 'verified', 'verifying', 'verizon', 'version', 'versus', 'very', 'via', 'vibrant', 'vibrate', 'vibrates', 'vibration', 'video', 'videos', 'vids', 'view', 'visual', 'voice', 'voicemail', 'voicemails', 'voltage', 'volume', 'voucher', 'vpn', 'vs', 'vzw', 'wack', 'wait', 'waited', 'waiting', 'waking', 'wall', 'wallet', 'wallpaper', 'wallpapers', 'want', 'wanted', 'wanting', 'wants', 'warmer', 'warning', 'warranty', 'was', 'wasn', 'wasnt', 'watch', 'watching', 'water', 'waterproof', 'wav', 'way', 'ways', 'we', 'weak', 'wearos', 'weather', 'web', 'webcam', 'webpages', 'website', 'websites', 'wedged', 'week', 'weekly', 'weight', 'weird', 'weirdly', 'well', 'wellbeing', 'went', 'were', 'weren', 'wet', 'what', 'whatsapp', 'wheel', 'when', 'whenever', 'where', 'which', 'while', 'white', 'whitestone', 'who', 'whole', 'why', 'wi', 'wide', 'widget', 'wife', 'wifi', 'will', 'windows', 'winner', 'wipe', 'wireless', 'wish', 'with', 'withholding', 'without', 'wobbly', 'wokring', 'won', 'wondering', 'wont', 'wooden', 'word', 'words', 'work', 'workaround', 'worker', 'working', 'works', 'world', 'worried', 'worse', 'worsen', 'worst', 'worth', 'would', 'wouldn', 'wrong', 'wtf', 'xbox', 'xi', 'xl', 'xperia', 'xr', 'xs', 'xxxxx', 'ya', 'yeah', 'year', 'years', 'yesterday', 'yet', 'you', 'your', 'youtube', 'yt', 'zip', 'zoom']\n"
     ]
    }
   ],
   "source": [
    "vocab = count_vec.get_feature_names()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the shape of testing and training data changes because countvectorozer converts the text data into matrix form. So it can be trained on those features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650442477876106"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv,y_train) \n",
    "y_pred_lr = lr.predict(X_test_cv)\n",
    "metrics.accuracy_score(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.67158671586715"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_cv,y_train) * 100# LR training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.50442477876106"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cv,y_test) * 100 # LR testing score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix \n",
    "Confusion matrix creates 2 X 2 matrix which shows the actual vs predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,  25],\n",
       "       [ 36, 191]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>36</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          200                         25\n",
       "Actual Google Pixel (1)                    36                        191"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m1 = metrics.confusion_matrix(y_test, y_pred_lr)\n",
    "cf_lr = pd.DataFrame(data=cf_m1, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic model has accuracy of 98.67 percent on training data, and 86.56 percent on testing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Classifier ( Multinomial ) model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849557522123894"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv,y_train)\n",
    "y_pred_nb = nb.predict(X_test_cv)\n",
    "metrics.accuracy_score(y_test,y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.64575645756457"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train_cv,y_train) * 100 # NB training Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.49557522123894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_cv,y_test) * 100 # NB testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[202,  23],\n",
       "       [ 29, 198]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>202</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>29</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          202                         23\n",
       "Actual Google Pixel (1)                    29                        198"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m2 = metrics.confusion_matrix(y_test, y_pred_nb)\n",
    "cf_nb = pd.DataFrame(data=cf_m2, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial model has accuracy of 95.64 percent on training data, and 88.49 percent on testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words (english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now going to play with stop words. I will use english stop words in countvectorizer and see if my results are any different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "count_vec_english = CountVectorizer(stop_words= english_stopwords)\n",
    "\n",
    "X_train_cv_e = count_vec_english.fit_transform(X_train)\n",
    "X_test_cv_e = count_vec_english.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 2116)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 2116)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv_e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using english stop words, shape of the data changed. Features decreased from 2238 to 2116. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805309734513275"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv_e,y_train)\n",
    "\n",
    "y_pred_lr_e = lr.predict(X_test_cv_e)\n",
    "metrics.accuracy_score(y_test,y_pred_lr_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.45018450184502"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_cv_e,y_train) * 100# LR training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.05309734513274"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cv_e,y_test) * 100 # LR testing score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207,  18],\n",
       "       [ 36, 191]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_lr_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>207</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>36</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          207                         18\n",
       "Actual Google Pixel (1)                    36                        191"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m3 = metrics.confusion_matrix(y_test, y_pred_lr_e)\n",
    "cf_lr_2 = pd.DataFrame(data=cf_m3, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_lr_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression with english stop words has accuracy of 98.45 % on training data, and 88.05 on testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Classifier ( Multinomial ) model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783185840707964"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv_e,y_train)\n",
    "\n",
    "y_pred_nb_e = nb.predict(X_test_cv_e)\n",
    "metrics.accuracy_score(y_test,y_pred_nb_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.64575645756457"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train_cv_e,y_train) * 100 # NB training Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.83185840707965"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_cv_e,y_test) * 100 # Nb testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,  29],\n",
       "       [ 26, 201]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_nb_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>202</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>29</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          202                         23\n",
       "Actual Google Pixel (1)                    29                        198"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m4 = metrics.confusion_matrix(y_test, y_pred_nb)\n",
    "cf_nb_2 = pd.DataFrame(data=cf_m4, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_nb_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial model with english stop words has accuracy of 95.64 percent on training data, and 87.83 percent on testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Stop words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In custom stop words, I am going to keep english stopwords and add 3 more. Three stop words i be using is manilty the subreddits names: iphone, google, pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = stopwords.words('english')\n",
    "custom_stopwords.extend(['iphone','google','pixel'])\n",
    "count_vec_custom = CountVectorizer(stop_words= custom_stopwords)\n",
    "\n",
    "X_train_cv_c = count_vec_custom.fit_transform(X_train)\n",
    "X_test_cv_c = count_vec_custom.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 2113)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 2113)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522123893805309"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv_c,y_train)\n",
    "\n",
    "y_pred_lr_c = lr.predict(X_test_cv_c)\n",
    "metrics.accuracy_score(y_test,y_pred_lr_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.38376383763838"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_cv_c,y_train) * 100# LR training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.22123893805309"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_cv_c,y_test) * 100 # LR testing score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166,  59],\n",
       "       [ 53, 174]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_lr_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>166</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>53</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          166                         59\n",
       "Actual Google Pixel (1)                    53                        174"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m5 = metrics.confusion_matrix(y_test, y_pred_lr_c)\n",
    "cf_nb_3 = pd.DataFrame(data=cf_m5, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_nb_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic regression model with custom stopwords accuracy for training is 96.38% and testing is 75.22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Classifier ( Multinomial ) model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7676991150442478"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intializing the model , fitting the mode, and predicting \n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv_c,y_train)\n",
    "\n",
    "y_pred_nb_c = nb.predict(X_test_cv_c)\n",
    "metrics.accuracy_score(y_test,y_pred_nb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.69372693726937"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train_cv_c,y_train) * 100 # NB training Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.76991150442478"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_cv_c,y_test) * 100 # NB testing score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  53],\n",
       "       [ 52, 175]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_nb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Iphone (0)</th>\n",
       "      <th>Predicted Google Pixel(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Iphone(0)</th>\n",
       "      <td>172</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Google Pixel (1)</th>\n",
       "      <td>52</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Predicted Iphone (0)  Predicted Google Pixel(1)\n",
       "Actual Iphone(0)                          172                         53\n",
       "Actual Google Pixel (1)                    52                        175"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_m6 = metrics.confusion_matrix(y_test, y_pred_nb_c)\n",
    "cf_nb_3 = pd.DataFrame(data=cf_m6, columns=['Predicted Iphone (0)', \n",
    "                                       'Predicted Google Pixel(1)'], \n",
    "                     index=['Actual Iphone(0)', 'Actual Google Pixel (1)'])\n",
    "cf_nb_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing all both models with different stop words, we can see there is huge difference in the accuracy of each model especailly with custom stop words. Basic approach to attacking a NLP problem is CCM: Collect, Clean, and Model. However, there is alot more goes into it, as we saw with stopwords and different models. CountVectorizer has many parameter, and I hope this basic approach is helpful. Next step could be to use different models such as Random forest, K-Nearest neighbor. Also, countvectorizer has many parameter. Best thing to do is play with different parameters. I could have gotten better result if i had more time to play with parameters. As of now, all of the models are overfitting because accuracy rate for training and testing is not the same. Best model thus far is Naive Bayes Multinomial with no stop words. The difference in accuracy is about 7 percent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
